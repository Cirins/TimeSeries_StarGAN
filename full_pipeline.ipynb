{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "%cd drive/MyDrive/ST/stargan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'realworld' # 'realworld' or 'cwru'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "seed = 2710\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "class MultiBranchClassifier(nn.Module):\n",
    "    def __init__(self, num_channels=3, num_domains=4, num_classes=5, num_timesteps=128):\n",
    "        super(MultiBranchClassifier, self).__init__()\n",
    "        # Shared layers\n",
    "        self.conv1 = nn.Conv1d(num_channels, 16, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.conv3 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.conv4 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "        self.fc_shared = nn.Linear(num_timesteps * 8, 100)\n",
    "\n",
    "        # Prepare class-specific branches as a single module with conditionally applied outputs\n",
    "        self.fc_class_branches = nn.Linear(100, 50 * num_classes)\n",
    "        self.fc_final = nn.Linear(50, num_domains * num_classes)\n",
    "\n",
    "    def forward(self, x, class_ids):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(self.relu(self.bn4(self.conv4(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc_shared(x))\n",
    "\n",
    "        # Process all class-specific branches simultaneously\n",
    "        class_branches = self.fc_class_branches(x).view(x.size(0), -1, 50)\n",
    "        class_outputs = class_branches[torch.arange(class_branches.size(0)), class_ids]\n",
    "\n",
    "        # Final class-specific output\n",
    "        final_outputs = self.fc_final(class_outputs.view(x.size(0), 50))\n",
    "        return final_outputs.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "def split_data(x, y, k, test_size=0.2, random_state=seed):\n",
    "    x_train, x_test, y_train, y_test, k_train, k_test = train_test_split(x, y, k,\n",
    "                                                                         test_size=test_size,\n",
    "                                                                         random_state=random_state,\n",
    "                                                                         stratify=k,\n",
    "                                                                         shuffle=True)\n",
    "    return x_train, x_test, y_train, y_test, k_train, k_test\n",
    "\n",
    "\n",
    "def setup_training(x_train, y_train, k_train, x_test, y_test, k_test, batch_size=64):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    k_train_tensor = torch.tensor(k_train, dtype=torch.long)\n",
    "    x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "    k_test_tensor = torch.tensor(k_test, dtype=torch.long)\n",
    "\n",
    "    # Create datasets and loaders\n",
    "    train_dataset = TensorDataset(x_train_tensor, y_train_tensor, k_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataset = TensorDataset(x_test_tensor, y_test_tensor, k_test_tensor)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, loss_fn, device='cpu'):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch, k_batch in test_loader:\n",
    "            x_batch, y_batch, k_batch = x_batch.to(device), y_batch.to(device), k_batch.to(device)\n",
    "            outputs = model(x_batch, y_batch)\n",
    "            loss = loss_fn(outputs, k_batch)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Assuming outputs are logits and k_batch are the true labels\n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted_labels == k_batch).sum().item()\n",
    "            total_predictions += k_batch.size(0)\n",
    "\n",
    "    total_loss /= len(test_loader)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    return total_loss, accuracy\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, test_loader, loss_fn, optimizer, epochs=300, name='domain_classifier'):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    loss_train = []\n",
    "    loss_test = []\n",
    "    accuracy_test = []\n",
    "    best_loss = np.inf\n",
    "\n",
    "    # Set up linear learning rate decay\n",
    "    lambda_lr = lambda epoch: 1 - epoch / epochs\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=lambda_lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x_batch, y_batch, k_batch in train_loader:\n",
    "            x_batch, y_batch, k_batch = x_batch.to(device), y_batch.to(device), k_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch, y_batch)\n",
    "            loss = loss_fn(outputs, k_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        total_loss /= len(train_loader)\n",
    "        loss_train.append(total_loss)\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        test_loss, test_accuracy = evaluate_model(model, test_loader, loss_fn, device=device)\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            best_model = model.state_dict().copy()\n",
    "        loss_test.append(test_loss)\n",
    "        accuracy_test.append(test_accuracy)\n",
    "\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - Train loss: {total_loss:.4f} - Test loss: {test_loss:.4f} - Test accuracy: {test_accuracy:.4f} - LR: {current_lr:.6f}\")\n",
    "\n",
    "    # Save best model\n",
    "    os.makedirs('pretrained_nets', exist_ok=True)\n",
    "    if best_model is not None:\n",
    "        print(f\"Saving best model at epoch {np.argmin(loss_test) + 1} and test loss {best_loss:.4f}\")\n",
    "        torch.save(best_model, f\"pretrained_nets/{name}.ckpt\")\n",
    "    else:\n",
    "        print(\"No best model found, saving current model\")\n",
    "        torch.save(model.state_dict(), f\"pretrained_nets/{name}.ckpt\")\n",
    "\n",
    "    return loss_train, loss_test, accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train domain classifier on Df\n",
    "\n",
    "if dataset == 'realworld':\n",
    "    dataset_name = 'realworld_128_3ch_4cl'\n",
    "    num_df_domains = 10\n",
    "    num_dp_domains = 5\n",
    "    num_classes = 4\n",
    "\n",
    "elif dataset == 'cwru':\n",
    "    dataset_name = 'cwru_256_3ch_5cl'\n",
    "    num_df_domains = 4\n",
    "    num_dp_domains = 4\n",
    "    num_classes = 5\n",
    "\n",
    "\n",
    "with open(f'data/{dataset_name}.pkl', 'rb') as f:\n",
    "    x, y, k = pickle.load(f)\n",
    "\n",
    "x = x[k < num_df_domains]\n",
    "y = y[k < num_df_domains]\n",
    "k = k[k < num_df_domains]\n",
    "print(x.shape, y.shape, k.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test, k_train, k_test = split_data(x, y, k, test_size=0.2, random_state=seed)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape, k_train.shape, k_test.shape)\n",
    "\n",
    "model = MultiBranchClassifier(num_domains=num_df_domains, num_classes=num_classes, num_timesteps=x_train.shape[2])\n",
    "\n",
    "train_loader, test_loader = setup_training(x_train, y_train, k_train, x_test, y_test, k_test)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "initial_lr = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
    "\n",
    "loss_train, loss_test, accuracy_test = train_model(model, train_loader, test_loader, loss_fn, optimizer, epochs=300, name=f'domain_classifier_{dataset}_df')\n",
    "\n",
    "# Find the best epoch based on the test loss\n",
    "best_epoch = np.argmin(loss_test)\n",
    "print(f\"Best epoch: {best_epoch + 1} - Test loss: {loss_test[best_epoch]:.4f} - Test accuracy: {accuracy_test[best_epoch]:.4f}\")\n",
    "\n",
    "# Plot the training and test loss displaying the best epoch with a vertical line\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(loss_train, label='Train loss')\n",
    "plt.plot(loss_test, label='Test loss')\n",
    "plt.axvline(best_epoch, color='r', linestyle='--')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot the test accuracy\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(accuracy_test, label='Test accuracy')\n",
    "plt.axvline(best_epoch, color='r', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train domain classifier on Dp\n",
    "\n",
    "with open(f'data/{dataset_name}.pkl', 'rb') as f:\n",
    "    x, y, k = pickle.load(f)\n",
    "\n",
    "with open(f'data/{dataset_name}_fs.pkl', 'rb') as f:\n",
    "    fs = pickle.load(f)\n",
    "\n",
    "x = x[fs == 0]\n",
    "y = y[fs == 0]\n",
    "k = k[fs == 0]\n",
    "x = x[k >= num_df_domains]\n",
    "y = y[k >= num_df_domains]\n",
    "k = k[k >= num_df_domains] - num_df_domains\n",
    "print(x.shape, y.shape, k.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test, k_train, k_test = split_data(x, y, k, test_size=0.2, random_state=seed)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape, k_train.shape, k_test.shape)\n",
    "\n",
    "model = MultiBranchClassifier(num_domains=num_dp_domains, num_classes=num_classes, num_timesteps=x_train.shape[2])\n",
    "\n",
    "train_loader, test_loader = setup_training(x_train, y_train, k_train, x_test, y_test, k_test)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "initial_lr = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
    "\n",
    "loss_train, loss_test, accuracy_test = train_model(model, train_loader, test_loader, loss_fn, optimizer, epochs=300, name=f'domain_classifier_{dataset}_dp')\n",
    "\n",
    "# Find the best epoch based on the test loss\n",
    "best_epoch = np.argmin(loss_test)\n",
    "print(f\"Best epoch: {best_epoch + 1} - Test loss: {loss_test[best_epoch]:.4f} - Test accuracy: {accuracy_test[best_epoch]:.4f}\")\n",
    "\n",
    "# Plot the training and test loss displaying the best epoch with a vertical line\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(loss_train, label='Train loss')\n",
    "plt.plot(loss_test, label='Test loss')\n",
    "plt.axvline(best_epoch, color='r', linestyle='--')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot the test accuracy\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(accuracy_test, label='Test accuracy')\n",
    "plt.axvline(best_epoch, color='r', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "seed = 2710\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "class MultiBranchSiameseNet(nn.Module):\n",
    "    def __init__(self, num_channels=3, num_classes=5, num_timesteps=128):\n",
    "        super(MultiBranchSiameseNet, self).__init__()\n",
    "        # Shared layers\n",
    "        self.conv1 = nn.Conv1d(num_channels, 16, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.conv3 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.conv4 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "        self.fc_shared = nn.Linear(num_timesteps * 8, 100)\n",
    "\n",
    "        # Class-specific branches\n",
    "        self.fc_class_branches = nn.Linear(100, 50 * num_classes)\n",
    "\n",
    "    def forward_once(self, x, class_id):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(self.relu(self.bn4(self.conv4(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc_shared(x))\n",
    "\n",
    "        # Process class-specific branch\n",
    "        class_branches = self.fc_class_branches(x).view(x.size(0), -1, 50)\n",
    "        class_output = class_branches[torch.arange(class_branches.size(0)), class_id]\n",
    "        return class_output\n",
    "\n",
    "\n",
    "def split_data(x, y, k, test_size=0.2, random_state=seed):\n",
    "    x_train, x_test, y_train, y_test, k_train, k_test = train_test_split(x, y, k,\n",
    "                                                                         test_size=test_size,\n",
    "                                                                         random_state=random_state,\n",
    "                                                                         stratify=k,\n",
    "                                                                         shuffle=True)\n",
    "    return x_train, x_test, y_train, y_test, k_train, k_test\n",
    "\n",
    "\n",
    "def setup_training(x_train, y_train, k_train, x_test, y_test, k_test, batch_size=64):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    k_train_tensor = torch.tensor(k_train, dtype=torch.long)\n",
    "    x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "    k_test_tensor = torch.tensor(k_test, dtype=torch.long)\n",
    "\n",
    "    # Create datasets and loaders\n",
    "    train_dataset = TensorDataset(x_train_tensor, y_train_tensor, k_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataset = TensorDataset(x_test_tensor, y_test_tensor, k_test_tensor)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cpu', margin=1.0):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    same_domain_distance = 0\n",
    "    diff_domain_distance = 0\n",
    "    same_domain_count = 0\n",
    "    diff_domain_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch, k_batch in test_loader:\n",
    "            x_batch, y_batch, k_batch = x_batch.to(device), y_batch.to(device), k_batch.to(device)\n",
    "            batch_size = x_batch.size(0)\n",
    "\n",
    "            # Compute all pairwise outputs\n",
    "            output1 = model.forward_once(x_batch.unsqueeze(1).expand(-1, batch_size, -1, -1).reshape(-1, x_batch.size(1), x_batch.size(2)),\n",
    "                                         y_batch.unsqueeze(1).expand(-1, batch_size).reshape(-1))\n",
    "            output2 = model.forward_once(x_batch.unsqueeze(0).expand(batch_size, -1, -1, -1).reshape(-1, x_batch.size(1), x_batch.size(2)),\n",
    "                                         y_batch.unsqueeze(0).expand(batch_size, -1).reshape(-1))\n",
    "\n",
    "            output1 = output1.view(batch_size, batch_size, -1)\n",
    "            output2 = output2.view(batch_size, batch_size, -1)\n",
    "\n",
    "            # Compute pairwise distances\n",
    "            euclidean_distances = F.pairwise_distance(output1, output2, keepdim=True).view(batch_size, batch_size)\n",
    "\n",
    "            # Compute pairwise labels\n",
    "            labels = (k_batch.unsqueeze(1) != k_batch.unsqueeze(0)).float()\n",
    "\n",
    "            # Compute loss\n",
    "            loss = (1 - labels) * torch.pow(euclidean_distances, 2) + labels * torch.pow(torch.clamp(margin - euclidean_distances, min=0.0), 2)\n",
    "            total_loss += loss.mean().item()\n",
    "\n",
    "            # Compute distances for same and different domains\n",
    "            same_domain_distance += euclidean_distances[labels == 0].sum().item()\n",
    "            diff_domain_distance += euclidean_distances[labels == 1].sum().item()\n",
    "            same_domain_count += (labels == 0).sum().item()\n",
    "            diff_domain_count += (labels == 1).sum().item()\n",
    "\n",
    "    total_loss /= len(test_loader)\n",
    "    avg_same_domain_distance = same_domain_distance / same_domain_count if same_domain_count > 0 else 0\n",
    "    avg_diff_domain_distance = diff_domain_distance / diff_domain_count if diff_domain_count > 0 else 0\n",
    "\n",
    "    return total_loss, avg_same_domain_distance, avg_diff_domain_distance\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, test_loader, optimizer, epochs=300, name='siamese_net', margin=1.0):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    loss_train = []\n",
    "    loss_test = []\n",
    "    avg_same_domain_distance_test = []\n",
    "    avg_diff_domain_distance_test = []\n",
    "    best_loss = np.inf\n",
    "\n",
    "    # Set up linear learning rate decay\n",
    "    lambda_lr = lambda epoch: 1 - epoch / epochs\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=lambda_lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x_batch, y_batch, k_batch in train_loader:\n",
    "            x_batch, y_batch, k_batch = x_batch.to(device), y_batch.to(device), k_batch.to(device)\n",
    "            batch_size = x_batch.size(0)\n",
    "\n",
    "            # Compute all pairwise outputs\n",
    "            output1 = model.forward_once(x_batch.unsqueeze(1).expand(-1, batch_size, -1, -1).reshape(-1, x_batch.size(1), x_batch.size(2)),\n",
    "                                         y_batch.unsqueeze(1).expand(-1, batch_size).reshape(-1))\n",
    "            output2 = model.forward_once(x_batch.unsqueeze(0).expand(batch_size, -1, -1, -1).reshape(-1, x_batch.size(1), x_batch.size(2)),\n",
    "                                         y_batch.unsqueeze(0).expand(batch_size, -1).reshape(-1))\n",
    "\n",
    "            output1 = output1.view(batch_size, batch_size, -1)\n",
    "            output2 = output2.view(batch_size, batch_size, -1)\n",
    "\n",
    "            # Compute pairwise distances\n",
    "            euclidean_distances = F.pairwise_distance(output1, output2, keepdim=True).view(batch_size, batch_size)\n",
    "\n",
    "            # Compute pairwise labels\n",
    "            labels = (k_batch.unsqueeze(1) != k_batch.unsqueeze(0)).float()\n",
    "\n",
    "            # Compute loss\n",
    "            loss = (1 - labels) * torch.pow(euclidean_distances, 2) + labels * torch.pow(torch.clamp(margin - euclidean_distances, min=0.0), 2)\n",
    "            total_loss += loss.mean().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss /= len(train_loader)\n",
    "        loss_train.append(total_loss)\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        test_loss, avg_same_domain_distance, avg_diff_domain_distance = evaluate_model(model, test_loader, device=device)\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            best_model = model.state_dict().copy()\n",
    "        loss_test.append(test_loss)\n",
    "        avg_same_domain_distance_test.append(avg_same_domain_distance)\n",
    "        avg_diff_domain_distance_test.append(avg_diff_domain_distance)\n",
    "\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - Train loss: {total_loss:.4f} - Test loss: {test_loss:.4f} - \"\n",
    "              f\"Avg same domain distance: {avg_same_domain_distance:.4f} - Avg diff domain distance: {avg_diff_domain_distance:.4f} - LR: {current_lr:.6f}\")\n",
    "\n",
    "    # Save best model\n",
    "    os.makedirs('pretrained_nets', exist_ok=True)\n",
    "    if best_model is not None:\n",
    "        print(f\"Saving best model at epoch {np.argmin(loss_test) + 1} and test loss {best_loss:.4f}\")\n",
    "        torch.save(best_model, f\"pretrained_nets/{name}.ckpt\")\n",
    "    else:\n",
    "        print(\"No best model found, saving current model\")\n",
    "        torch.save(model.state_dict(), f\"pretrained_nets/{name}.ckpt\")\n",
    "\n",
    "    return loss_train, loss_test, avg_same_domain_distance_test, avg_diff_domain_distance_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Siamese network on Df\n",
    "\n",
    "if dataset == 'realworld':\n",
    "    dataset_name = 'realworld_128_3ch_4cl'\n",
    "    num_df_domains = 10\n",
    "    num_dp_domains = 5\n",
    "    num_classes = 4\n",
    "\n",
    "elif dataset == 'cwru':\n",
    "    dataset_name = 'cwru_256_3ch_5cl'\n",
    "    num_df_domains = 4\n",
    "    num_dp_domains = 4\n",
    "    num_classes = 5\n",
    "    \n",
    "\n",
    "with open(f'data/{dataset_name}.pkl', 'rb') as f:\n",
    "    x, y, k = pickle.load(f)\n",
    "\n",
    "x = x[k < num_df_domains]\n",
    "y = y[k < num_df_domains]\n",
    "k = k[k < num_df_domains]\n",
    "print(x.shape, y.shape, k.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test, k_train, k_test = split_data(x, y, k, test_size=0.2, random_state=seed)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape, k_train.shape, k_test.shape)\n",
    "\n",
    "model = MultiBranchSiameseNet(num_classes=num_classes, num_timesteps=x_train.shape[2])\n",
    "\n",
    "train_loader, test_loader = setup_training(x_train, y_train, k_train, x_test, y_test, k_test)\n",
    "\n",
    "initial_lr = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
    "\n",
    "loss_train, loss_test, avg_same_domain_distance_test, avg_diff_domain_distance_test = train_model(model, train_loader, test_loader, optimizer, epochs=200, name=f'siamese_net_{dataset}_df')\n",
    "\n",
    "# Find the best epoch based on the test loss\n",
    "best_epoch = np.argmin(loss_test)\n",
    "print(f\"Best epoch: {best_epoch + 1} - Test loss: {loss_test[best_epoch]:.4f} - Avg same domain distance: {avg_same_domain_distance_test[best_epoch]:.4f} - Avg diff domain distance: {avg_diff_domain_distance_test[best_epoch]:.4f}\")\n",
    "\n",
    "# Plot the training and test loss displaying the best epoch with a vertical line\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(loss_train, label='Train loss')\n",
    "plt.plot(loss_test, label='Test loss')\n",
    "plt.axvline(best_epoch, color='r', linestyle='--')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot the average same domain distance\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(avg_same_domain_distance_test, label='Avg same domain distance')\n",
    "plt.axvline(best_epoch, color='r', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Avg Same Domain Distance')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot the average different domain distance\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(avg_diff_domain_distance_test, label='Avg diff domain distance')\n",
    "plt.axvline(best_epoch, color='r', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Avg Diff Domain Distance')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train domain classifier on Dp\n",
    "\n",
    "with open(f'data/{dataset_name}.pkl', 'rb') as f:\n",
    "    x, y, k = pickle.load(f)\n",
    "\n",
    "with open(f'data/{dataset_name}_fs.pkl', 'rb') as f:\n",
    "    fs = pickle.load(f)\n",
    "\n",
    "x = x[fs == 0]\n",
    "y = y[fs == 0]\n",
    "k = k[fs == 0]\n",
    "x = x[k >= num_df_domains]\n",
    "y = y[k >= num_df_domains]\n",
    "k = k[k >= num_df_domains] - num_df_domains\n",
    "print(x.shape, y.shape, k.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test, k_train, k_test = split_data(x, y, k, test_size=0.2, random_state=seed)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape, k_train.shape, k_test.shape)\n",
    "\n",
    "model = MultiBranchSiameseNet(num_classes=num_classes, num_timesteps=x_train.shape[2])\n",
    "\n",
    "train_loader, test_loader = setup_training(x_train, y_train, k_train, x_test, y_test, k_test)\n",
    "\n",
    "initial_lr = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
    "\n",
    "loss_train, loss_test, avg_same_domain_distance_test, avg_diff_domain_distance_test = train_model(model, train_loader, test_loader, optimizer, epochs=200, name=f'siamese_net_{dataset}_dp')\n",
    "\n",
    "# Find the best epoch based on the test loss\n",
    "best_epoch = np.argmin(loss_test)\n",
    "print(f\"Best epoch: {best_epoch + 1} - Test loss: {loss_test[best_epoch]:.4f} - Avg same domain distance: {avg_same_domain_distance_test[best_epoch]:.4f} - Avg diff domain distance: {avg_diff_domain_distance_test[best_epoch]:.4f}\")\n",
    "\n",
    "# Plot the training and test loss displaying the best epoch with a vertical line\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(loss_train, label='Train loss')\n",
    "plt.plot(loss_test, label='Test loss')\n",
    "plt.axvline(best_epoch, color='r', linestyle='--')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot the average same domain distance\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(avg_same_domain_distance_test, label='Avg same domain distance')\n",
    "plt.axvline(best_epoch, color='r', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Avg Same Domain Distance')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot the average different domain distance\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(avg_diff_domain_distance_test, label='Avg diff domain distance')\n",
    "plt.axvline(best_epoch, color='r', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Avg Diff Domain Distance')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "if dataset == 'realworld':\n",
    "    dataset_name = 'realworld_128_3ch_4cl'\n",
    "    class_names = ['WAL', 'RUN', 'CLD', 'CLU']\n",
    "    channel_names = ['X', 'Y', 'Z']\n",
    "\n",
    "    num_timesteps = 128\n",
    "    num_channels = 3\n",
    "    num_train_domains = 10\n",
    "    num_test_domains = 5\n",
    "    num_classes = 4\n",
    "\n",
    "    lambda_cyc = 10\n",
    "    lambda_id = 10\n",
    "    lambda_dom = 0.1\n",
    "    lambda_ds = 1\n",
    "\n",
    "    total_iters = 300000\n",
    "\n",
    "elif dataset == 'cwru':\n",
    "    dataset_name = 'cwru_256_3ch_5cl'\n",
    "    class_names = ['IR', 'Ball', 'OR_centred', 'OR_orthogonal', 'OR_opposite']\n",
    "    channel_names = ['DE', 'FE', 'BA']\n",
    "\n",
    "    num_timesteps = 256\n",
    "    num_channels = 3\n",
    "    num_train_domains = 4\n",
    "    num_test_domains = 4\n",
    "    num_classes = 5\n",
    "\n",
    "    lambda_cyc = 100\n",
    "    lambda_id = 100\n",
    "    lambda_dom = 0.01\n",
    "    lambda_ds = 1\n",
    "\n",
    "    total_iters = 200000\n",
    "\n",
    "\n",
    "print_every = 100\n",
    "save_every = 10000\n",
    "sample_every = 1000\n",
    "eval_every = -1\n",
    "\n",
    "\n",
    "# Launch training\n",
    "print('Starting training phase...\\n\\n')\n",
    "subprocess.run(['python', 'main.py',\n",
    "                '--mode', 'train',\n",
    "                '--dataset', dataset,\n",
    "                '--dataset_name', dataset_name,\n",
    "                '--class_names', ','.join(class_names),\n",
    "                '--channel_names', ','.join(channel_names),\n",
    "                '--num_timesteps', str(num_timesteps),\n",
    "                '--num_channels', str(num_channels),\n",
    "                '--num_train_domains', str(num_train_domains),\n",
    "                '--num_test_domains', str(num_test_domains),\n",
    "                '--num_classes', str(num_classes),\n",
    "                '--lambda_cyc', str(lambda_cyc),\n",
    "                '--lambda_id', str(lambda_id),\n",
    "                '--lambda_dom', str(lambda_dom),\n",
    "                '--lambda_ds', str(lambda_ds),\n",
    "                '--print_every', str(print_every),\n",
    "                '--save_every', str(save_every),\n",
    "                '--sample_every', str(sample_every),\n",
    "                '--eval_every', str(eval_every),\n",
    "                '--total_iters', str(total_iters)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch evaluation\n",
    "print('Starting evaluation phase...\\n\\n')\n",
    "subprocess.run(['python', 'main.py',\n",
    "                '--mode', 'eval',\n",
    "                '--dataset', dataset,\n",
    "                '--dataset_name', dataset_name,\n",
    "                '--class_names', ','.join(class_names),\n",
    "                '--channel_names', ','.join(channel_names),\n",
    "                '--num_timesteps', str(num_timesteps),\n",
    "                '--num_channels', str(num_channels),\n",
    "                '--num_train_domains', str(num_train_domains),\n",
    "                '--num_test_domains', str(num_test_domains),\n",
    "                '--num_classes', str(num_classes),\n",
    "                '--resume_iter', str(total_iters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSTR Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstr_scores = pd.read_csv(f'expr_{dataset}/eval/tstr_scores.csv')\n",
    "tstr_scores = tstr_scores.drop(columns=['step', 'loss'])\n",
    "tstr_scores.head()\n",
    "\n",
    "tstr_scores_ref = tstr_scores[tstr_scores['mode'] == 'reference']\n",
    "\n",
    "print('Reference TSTR Scores:')\n",
    "for source in tstr_scores_ref['source'].unique():\n",
    "    print(f\"Source: {source}\")\n",
    "    for domain in tstr_scores_ref['domain'].unique():\n",
    "        acc = tstr_scores_ref[(tstr_scores_ref['source'] == source) & (tstr_scores_ref['domain'] == domain)]['accuracy'].values[0]\n",
    "        print(f\"\\tDomain: {domain}, Accuracy: {acc:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Average TSTR Scores:')\n",
    "for source in tstr_scores_ref['source'].unique():\n",
    "    acc = tstr_scores_ref[tstr_scores_ref['source'] == source]['accuracy'].mean()\n",
    "    print(f\"Source: {source}, Average Accuracy: {acc:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "acc = tstr_scores_ref['accuracy'].mean()\n",
    "print(f\"Average Accuracy: {acc:.2f}\")\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "tstr_scores_lat = tstr_scores[tstr_scores['mode'] == 'latent']\n",
    "\n",
    "print('Latent TSTR Scores:')\n",
    "for source in tstr_scores_lat['source'].unique():\n",
    "    print(f\"Source: {source}\")\n",
    "    for domain in tstr_scores_lat['domain'].unique():\n",
    "        acc = tstr_scores_lat[(tstr_scores_lat['source'] == source) & (tstr_scores_lat['domain'] == domain)]['accuracy'].values[0]\n",
    "        print(f\"\\tDomain: {domain}, Accuracy: {acc:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Average TSTR Scores:')\n",
    "for source in tstr_scores_lat['source'].unique():\n",
    "    acc = tstr_scores_lat[tstr_scores_lat['source'] == source]['accuracy'].mean()\n",
    "    print(f\"Source: {source}, Average Accuracy: {acc:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "acc = tstr_scores_lat['accuracy'].mean()\n",
    "print(f\"Average Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_scores = pd.read_csv(f'expr_{dataset}/eval/domain_scores.csv')\n",
    "domain_scores = domain_scores.drop(columns=['step', 'loss'])\n",
    "\n",
    "domain_scores_ref = domain_scores[domain_scores['mode'] == 'reference']\n",
    "\n",
    "print('Reference Domain Scores:')\n",
    "for source in domain_scores_ref['source'].unique():\n",
    "    print(f\"Source: {source}\")\n",
    "    for target in domain_scores_ref['target'].unique():\n",
    "        if source == target:\n",
    "            continue\n",
    "        acc = domain_scores_ref[(domain_scores_ref['source'] == source) & (domain_scores_ref['target'] == target)]['accuracy'].values[0]\n",
    "        print(f\"\\tTarget: {target}, Accuracy: {acc:.2f}\")\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "print('Average Domain Scores:')\n",
    "for source in domain_scores_ref['source'].unique():\n",
    "    acc = domain_scores_ref[domain_scores_ref['source'] == source]['accuracy'].mean()\n",
    "    print(f\"Source: {source}, Average Accuracy: {acc:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "acc = domain_scores_ref['accuracy'].mean()\n",
    "print(f\"Average Accuracy: {acc:.2f}\")\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "domain_scores_lat = domain_scores[domain_scores['mode'] == 'latent']\n",
    "\n",
    "print('Latent Domain Scores:')\n",
    "for source in domain_scores_lat['source'].unique():\n",
    "    print(f\"Source: {source}\")\n",
    "    for target in domain_scores_lat['target'].unique():\n",
    "        if source == target:\n",
    "            continue\n",
    "        acc = domain_scores_lat[(domain_scores_lat['source'] == source) & (domain_scores_lat['target'] == target)]['accuracy'].values[0]\n",
    "        print(f\"\\tTarget: {target}, Accuracy: {acc:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Average Domain Scores:')\n",
    "for source in domain_scores_lat['source'].unique():\n",
    "    acc = domain_scores_lat[domain_scores_lat['source'] == source]['accuracy'].mean()\n",
    "    print(f\"Source: {source}, Average Accuracy: {acc:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "acc = domain_scores_lat['accuracy'].mean()\n",
    "print(f\"Average Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_scores = pd.read_csv(f'expr_{dataset}/eval/dist_scores.csv')\n",
    "distance_scores = distance_scores.drop(columns=['step'])\n",
    "\n",
    "distance_scores_ref = distance_scores[distance_scores['mode'] == 'reference']\n",
    "\n",
    "print('Reference Distance Scores:')\n",
    "for source in distance_scores_ref['source'].unique():\n",
    "    print(f\"Source: {source}\")\n",
    "    for target in distance_scores_ref['target'].unique():\n",
    "        if source == target:\n",
    "            continue\n",
    "        print(f\"\\tTarget: {target}\")\n",
    "        for domain in distance_scores_ref['domain'].unique():\n",
    "            dist = distance_scores_ref[(distance_scores_ref['source'] == source) & (distance_scores_ref['target'] == target) & (distance_scores_ref['domain'] == domain)]['distance'].values[0]\n",
    "            print(f\"\\t\\tDomain: {domain}, Distance: {dist:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Average Distance Scores:')\n",
    "for source in distance_scores_ref['source'].unique():\n",
    "    dist = distance_scores_ref[distance_scores_ref['source'] == source]['distance'].mean()\n",
    "    print(f\"Source: {source}, Average Distance: {dist:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "dist = distance_scores_ref['distance'].mean()\n",
    "print(f\"Average Distance: {dist:.2f}\")\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "distance_scores_lat = distance_scores[distance_scores['mode'] == 'latent']\n",
    "\n",
    "print('Latent Distance Scores:')\n",
    "for source in distance_scores_lat['source'].unique():\n",
    "    print(f\"Source: {source}\")\n",
    "    for target in distance_scores_lat['target'].unique():\n",
    "        if source == target:\n",
    "            continue\n",
    "        print(f\"\\tTarget: {target}\")\n",
    "        for domain in distance_scores_lat['domain'].unique():\n",
    "            dist = distance_scores_lat[(distance_scores_lat['source'] == source) & (distance_scores_lat['target'] == target) & (distance_scores_lat['domain'] == domain)]['distance'].values[0]\n",
    "            print(f\"\\t\\tDomain: {domain}, Distance: {dist:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Average Distance Scores:')\n",
    "for source in distance_scores_lat['source'].unique():\n",
    "    dist = distance_scores_lat[distance_scores_lat['source'] == source]['distance'].mean()\n",
    "    print(f\"Source: {source}, Average Distance: {dist:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "dist = distance_scores_lat['distance'].mean()\n",
    "print(f\"Average Distance: {dist:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "if dataset == 'realworld':\n",
    "    dataset_name = 'realworld_128_3ch_4cl'\n",
    "    class_names = ['WAL', 'RUN', 'CLD', 'CLU']\n",
    "    channel_names = ['X', 'Y', 'Z']\n",
    "\n",
    "    num_timesteps = 128\n",
    "    num_channels = 3\n",
    "    num_train_domains = 10\n",
    "    num_test_domains = 5\n",
    "    num_classes = 4\n",
    "\n",
    "    lambda_cyc = 10\n",
    "    lambda_id = 10\n",
    "    lambda_dom = 0.1\n",
    "    lambda_ds = 1\n",
    "\n",
    "    total_iters = 10000\n",
    "\n",
    "elif dataset == 'cwru':\n",
    "    dataset_name = 'cwru_256_3ch_5cl'\n",
    "    class_names = ['IR', 'Ball', 'OR_centred', 'OR_orthogonal', 'OR_opposite']\n",
    "    channel_names = ['DE', 'FE', 'BA']\n",
    "\n",
    "    num_timesteps = 256\n",
    "    num_channels = 3\n",
    "    num_train_domains = 4\n",
    "    num_test_domains = 4\n",
    "    num_classes = 5\n",
    "\n",
    "    lambda_cyc = 100\n",
    "    lambda_id = 100\n",
    "    lambda_dom = 0.01\n",
    "    lambda_ds = 1\n",
    "\n",
    "    total_iters = 10000\n",
    "\n",
    "\n",
    "print_every = 100\n",
    "save_every = 10000\n",
    "sample_every = 1000\n",
    "eval_every = -1\n",
    "\n",
    "\n",
    "# Launch training\n",
    "print('Starting training phase...\\n\\n')\n",
    "subprocess.run(['python', 'main.py',\n",
    "                '--mode', 'finetune',\n",
    "                '--dataset', dataset,\n",
    "                '--dataset_name', dataset_name,\n",
    "                '--class_names', ','.join(class_names),\n",
    "                '--channel_names', ','.join(channel_names),\n",
    "                '--num_timesteps', str(num_timesteps),\n",
    "                '--num_channels', str(num_channels),\n",
    "                '--num_train_domains', str(num_train_domains),\n",
    "                '--num_test_domains', str(num_test_domains),\n",
    "                '--num_classes', str(num_classes),\n",
    "                '--lambda_cyc', str(lambda_cyc),\n",
    "                '--lambda_id', str(lambda_id),\n",
    "                '--lambda_dom', str(lambda_dom),\n",
    "                '--lambda_ds', str(lambda_ds),\n",
    "                '--print_every', str(print_every),\n",
    "                '--save_every', str(save_every),\n",
    "                '--sample_every', str(sample_every),\n",
    "                '--eval_every', str(eval_every),\n",
    "                '--total_iters', str(total_iters)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch evaluation\n",
    "print('Starting evaluation phase...\\n\\n')\n",
    "subprocess.run(['python', 'main.py',\n",
    "                '--mode', 'eval',\n",
    "                '--dataset', dataset,\n",
    "                '--dataset_name', dataset_name,\n",
    "                '--class_names', ','.join(class_names),\n",
    "                '--channel_names', ','.join(channel_names),\n",
    "                '--num_timesteps', str(num_timesteps),\n",
    "                '--num_channels', str(num_channels),\n",
    "                '--num_train_domains', str(num_train_domains),\n",
    "                '--num_test_domains', str(num_test_domains),\n",
    "                '--num_classes', str(num_classes),\n",
    "                '--resume_iter', str(total_iters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSTR Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstr_scores = pd.read_csv(f'expr_{dataset}/eval/tstr_scores.csv')\n",
    "tstr_scores = tstr_scores.drop(columns=['step', 'loss'])\n",
    "tstr_scores.head()\n",
    "\n",
    "tstr_scores_ref = tstr_scores[tstr_scores['mode'] == 'reference']\n",
    "\n",
    "print('Reference TSTR Scores:')\n",
    "for source in tstr_scores_ref['source'].unique():\n",
    "    print(f\"Source: {source}\")\n",
    "    for domain in tstr_scores_ref['domain'].unique():\n",
    "        acc = tstr_scores_ref[(tstr_scores_ref['source'] == source) & (tstr_scores_ref['domain'] == domain)]['accuracy'].values[0]\n",
    "        print(f\"\\tDomain: {domain}, Accuracy: {acc:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Average TSTR Scores:')\n",
    "for source in tstr_scores_ref['source'].unique():\n",
    "    acc = tstr_scores_ref[tstr_scores_ref['source'] == source]['accuracy'].mean()\n",
    "    print(f\"Source: {source}, Average Accuracy: {acc:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "acc = tstr_scores_ref['accuracy'].mean()\n",
    "print(f\"Average Accuracy: {acc:.2f}\")\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "tstr_scores_lat = tstr_scores[tstr_scores['mode'] == 'latent']\n",
    "\n",
    "print('Latent TSTR Scores:')\n",
    "for source in tstr_scores_lat['source'].unique():\n",
    "    print(f\"Source: {source}\")\n",
    "    for domain in tstr_scores_lat['domain'].unique():\n",
    "        acc = tstr_scores_lat[(tstr_scores_lat['source'] == source) & (tstr_scores_lat['domain'] == domain)]['accuracy'].values[0]\n",
    "        print(f\"\\tDomain: {domain}, Accuracy: {acc:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Average TSTR Scores:')\n",
    "for source in tstr_scores_lat['source'].unique():\n",
    "    acc = tstr_scores_lat[tstr_scores_lat['source'] == source]['accuracy'].mean()\n",
    "    print(f\"Source: {source}, Average Accuracy: {acc:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "acc = tstr_scores_lat['accuracy'].mean()\n",
    "print(f\"Average Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_scores = pd.read_csv(f'expr_{dataset}/eval/domain_scores.csv')\n",
    "domain_scores = domain_scores.drop(columns=['step', 'loss'])\n",
    "\n",
    "domain_scores_ref = domain_scores[domain_scores['mode'] == 'reference']\n",
    "\n",
    "print('Reference Domain Scores:')\n",
    "for source in domain_scores_ref['source'].unique():\n",
    "    print(f\"Source: {source}\")\n",
    "    for target in domain_scores_ref['target'].unique():\n",
    "        if source == target:\n",
    "            continue\n",
    "        acc = domain_scores_ref[(domain_scores_ref['source'] == source) & (domain_scores_ref['target'] == target)]['accuracy'].values[0]\n",
    "        print(f\"\\tTarget: {target}, Accuracy: {acc:.2f}\")\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "print('Average Domain Scores:')\n",
    "for source in domain_scores_ref['source'].unique():\n",
    "    acc = domain_scores_ref[domain_scores_ref['source'] == source]['accuracy'].mean()\n",
    "    print(f\"Source: {source}, Average Accuracy: {acc:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "acc = domain_scores_ref['accuracy'].mean()\n",
    "print(f\"Average Accuracy: {acc:.2f}\")\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "domain_scores_lat = domain_scores[domain_scores['mode'] == 'latent']\n",
    "\n",
    "print('Latent Domain Scores:')\n",
    "for source in domain_scores_lat['source'].unique():\n",
    "    print(f\"Source: {source}\")\n",
    "    for target in domain_scores_lat['target'].unique():\n",
    "        if source == target:\n",
    "            continue\n",
    "        acc = domain_scores_lat[(domain_scores_lat['source'] == source) & (domain_scores_lat['target'] == target)]['accuracy'].values[0]\n",
    "        print(f\"\\tTarget: {target}, Accuracy: {acc:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Average Domain Scores:')\n",
    "for source in domain_scores_lat['source'].unique():\n",
    "    acc = domain_scores_lat[domain_scores_lat['source'] == source]['accuracy'].mean()\n",
    "    print(f\"Source: {source}, Average Accuracy: {acc:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "acc = domain_scores_lat['accuracy'].mean()\n",
    "print(f\"Average Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_scores = pd.read_csv(f'expr_{dataset}/eval/dist_scores.csv')\n",
    "distance_scores = distance_scores.drop(columns=['step'])\n",
    "\n",
    "distance_scores_ref = distance_scores[distance_scores['mode'] == 'reference']\n",
    "\n",
    "print('Reference Distance Scores:')\n",
    "for source in distance_scores_ref['source'].unique():\n",
    "    print(f\"Source: {source}\")\n",
    "    for target in distance_scores_ref['target'].unique():\n",
    "        if source == target:\n",
    "            continue\n",
    "        print(f\"\\tTarget: {target}\")\n",
    "        for domain in distance_scores_ref['domain'].unique():\n",
    "            dist = distance_scores_ref[(distance_scores_ref['source'] == source) & (distance_scores_ref['target'] == target) & (distance_scores_ref['domain'] == domain)]['distance'].values[0]\n",
    "            print(f\"\\t\\tDomain: {domain}, Distance: {dist:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Average Distance Scores:')\n",
    "for source in distance_scores_ref['source'].unique():\n",
    "    dist = distance_scores_ref[distance_scores_ref['source'] == source]['distance'].mean()\n",
    "    print(f\"Source: {source}, Average Distance: {dist:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "dist = distance_scores_ref['distance'].mean()\n",
    "print(f\"Average Distance: {dist:.2f}\")\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "distance_scores_lat = distance_scores[distance_scores['mode'] == 'latent']\n",
    "\n",
    "print('Latent Distance Scores:')\n",
    "for source in distance_scores_lat['source'].unique():\n",
    "    print(f\"Source: {source}\")\n",
    "    for target in distance_scores_lat['target'].unique():\n",
    "        if source == target:\n",
    "            continue\n",
    "        print(f\"\\tTarget: {target}\")\n",
    "        for domain in distance_scores_lat['domain'].unique():\n",
    "            dist = distance_scores_lat[(distance_scores_lat['source'] == source) & (distance_scores_lat['target'] == target) & (distance_scores_lat['domain'] == domain)]['distance'].values[0]\n",
    "            print(f\"\\t\\tDomain: {domain}, Distance: {dist:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Average Distance Scores:')\n",
    "for source in distance_scores_lat['source'].unique():\n",
    "    dist = distance_scores_lat[distance_scores_lat['source'] == source]['distance'].mean()\n",
    "    print(f\"Source: {source}, Average Distance: {dist:.2f}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "dist = distance_scores_lat['distance'].mean()\n",
    "print(f\"Average Distance: {dist:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stargan-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
